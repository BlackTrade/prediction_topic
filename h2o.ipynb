{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://megawiki.megafon.ru/pages/viewpage.action?pageId=617546257"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Kluster\n",
    "\n",
    "Kluster mode of Sparkling Water supports connection to external H2O clusters (standalone/hadoop). The H2O cluster needs to be started with a corresponding H2O, which can be downloaded as below.\n",
    "\n",
    "1. Download and unpack Sparkling Water distribution\n",
    "\n",
    "2. Download corresponding H2O driver for your Hadoop distribution (e.g., hdp2.2, cdh5.4) or standalone one:\n",
    "export H2O_DRIVER_JAR=$(/path/to/sparkling-water-3.30.0.6-1-2.3/bin/get-h2o-driver.sh hdp2.2)\n",
    "\n",
    "3. Set path to sparkling-water-assembly-extensions-3.30.0.6-1-2.3-all.jar which is bundled in Sparkling Water archive:\n",
    "SW_EXTENSIONS_ASSEMBLY=/path/to/sparkling-water-3.30.0.6-1-2.3/jars/sparkling-water-assembly-extensions-3.30.0.6-1-2.3-all.jar\n",
    "\n",
    "4. Start H2O cluster on Hadoop:\n",
    "hadoop -jar $H2O_DRIVER_JAR -libjars $SW_EXTENSIONS_ASSEMBLY -sw_ext_backend -jobname test -nodes 3 -mapperXmx 6g\n",
    "\n",
    "5. In your Sparkling Water application, create H2OContext:\n",
    "\n",
    "Scala\n",
    "import org.apache.spark.h2o._\n",
    "val conf = new H2OConf().setExternalClusterMode().useManualClusterStart().setCloudName(\"test\")\n",
    "val hc = H2OContext.getOrCreate(conf)\n",
    "\n",
    "Python\n",
    "from pysparkling import *\n",
    "conf = H2OConf().setExternalClusterMode().useManualClusterStart().setCloudName(\"test\")\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hadoop jar /home/pkrylov/h2o/h2odriver.jar -baseport 50001 -n 2 -mapperXmx 6g -jobname h2o -driverif 10.199.246.181 -dri             verport 9001\n",
    "\n",
    "[pkrylov@msk-wrk-devgpu01 ~]$ hostname -I  10.199.246.181\n",
    "\n",
    "Using mapper->driver callback IP address and port: 10.199.246.181:9001\n",
    "(You can override these with -driverif and -driverport/-driverportrange and/or specify external IP using -extdriverif.)\n",
    "Memory Settings:\n",
    "    mapreduce.map.java.opts:     -Xms6g -Xmx6g -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Dlog4j.defaultInitOverride=true\n",
    "    Extra memory percent:        10\n",
    "    mapreduce.map.memory.mb:     6758\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/configuration/configuration_properties.html\n",
    "\n",
    "spark.ext.h2o.backend.cluster.mode\n",
    "\t\n",
    "internal\t\n",
    "\n",
    "setInternalClusterMode()\n",
    "setExternalClusterMode()\n",
    "\t\n",
    "\n",
    "This option can be set either to internal or external. When set to external, H2O Context is created by connecting to existing H2O cluster, otherwise H2O cluster located inside Spark is created. That means that each Spark executor will have one H2O instance running in it. The internal mode is not recommended for big clusters and clusters where Spark executors are not stable.\n",
    "\n",
    "\n",
    "import org.apache.spark.h2o._\n",
    "val conf =new H2OConf(spark).setExternalClusterMode()\n",
    "                            .useAutoClusterStart()\n",
    "                            .setH2ODriverPath(\"/home/hadoop/h2odriver-sw2.2.7-hdp2.6-extended.jar\")\n",
    "                            .setNumOfExternalH2ONodes(1)\n",
    "                            .setMapperXmx(\"2G\")\n",
    "                            .set(\"spark.ext.h2o.external.driver.if\",\"10.6.40.219\")\n",
    "                            \n",
    "val hc = H2OContext.getOrCreate(spark, conf)\n",
    "\n",
    "https://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.3/29/doc/deployment/backends.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXECUTORS = 32\n",
    "EXECUTOR_CORES = 2\n",
    "SPARK_NAME = 'sparkling_water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.3.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.10 (default, Mar 25 2020 23:51:54)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 30 --master yarn --name claims_1 pyspark-shell'\n",
    "\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] =  \"\"\"--master yarn \\\n",
    "                                        --deploy-mode client \\\n",
    "                                        --num-executors {NUM_EXECUTORS} \\\n",
    "                                        --executor-cores {EXECUTOR_CORES} \\\n",
    "                                        --executor-memory 15G \\\n",
    "                                        --driver-memory 10G \\\n",
    "                                        --name {SPARK_NAME} pyspark-shell\n",
    "                                        \"\"\".format(NUM_EXECUTORS=NUM_EXECUTORS, \n",
    "                                                   EXECUTOR_CORES=EXECUTOR_CORES, \n",
    "                                                   SPARK_NAME=SPARK_NAME)\n",
    "\n",
    "PYTHON = 'python3.4'\n",
    "\n",
    "#os.environ[\"PYSPARK_DRIVER_PYTHON\"]='jupyter'\n",
    "#os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]='notebook'\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYTHON\n",
    "os.environ[\"SPARK_YARN_USER_ENV\"] = PYTHON\n",
    "\n",
    "os.environ[\"SPARK_HOME\"]='/var/local/spark-2.3.2'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://msk-wrk-devgpu01.megafon.ru:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sparkling_water</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa88326dc50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/home/pkrylov/h2o\"\n",
    "h2o_pysparkling = \"{DIR}/h2o_pysparkling_2.3-3.30.0.6-1-2.3.zip\".format(DIR = DIR)\n",
    "spark.sparkContext.addPyFile(h2o_pysparkling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysparkling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DRIVER\n",
    "[pkrylov@msk-wrk-devgpu01 ~]$ hostname -I  10.199.246.181\n",
    "\n",
    "NODES\n",
    "[pkrylov@msk-hdp-ppdn16 ~]$ hostname -I    10.199.246.147\n",
    "[pkrylov@msk-hdp-ppdn19 ~]$ hostname -I    10.199.246.150\n",
    "[pkrylov@msk-hdp-ppdn27 ~]$ hostname -I    10.199.246.158\n",
    "[pkrylov@msk-hdp-ppdn24 ~]$ hostname -I    10.199.246.155\n",
    "[pkrylov@msk-hdp-ppdn02 ~]$ hostname -I    10.199.246.133\n",
    "[pkrylov@msk-hdp-ppdn06 ~]$ hostname -I    10.199.246.137 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_cluster_ip = '10.199.246.137'\n",
    "h2o_cluster_port = 54321\n",
    "h2o_name = 'h2o_s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method 'setH2OCluster(ip, port)' also sets backend to external. This side effect will be removed in the version in 3.32.\n"
     ]
    }
   ],
   "source": [
    "conf = (H2OConf().setExternalClusterMode()\n",
    "                      .useManualClusterStart()                      \n",
    "                      .setH2OCluster(h2o_cluster_ip, h2o_cluster_port)\n",
    "                      .setCloudName(h2o_name)\n",
    "                      .set(\"spark.ext.h2o.backend.cluster.mode\", \"external\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.30.0.6-1-2.3\n",
      " * H2O name: pkrylov\n",
      " * cluster size: 32\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,10.199.246.132,54321)\n",
      "  (1,10.199.246.132,54323)\n",
      "  (2,10.199.246.132,54325)\n",
      "  (3,10.199.246.133,54321)\n",
      "  (4,10.199.246.133,54323)\n",
      "  (5,10.199.246.133,54325)\n",
      "  (6,10.199.246.137,54321)\n",
      "  (7,10.199.246.137,54323)\n",
      "  (8,10.199.246.137,54325)\n",
      "  (9,10.199.246.139,54321)\n",
      "  (10,10.199.246.139,54323)\n",
      "  (11,10.199.246.139,54325)\n",
      "  (12,10.199.246.140,54321)\n",
      "  (13,10.199.246.140,54323)\n",
      "  (14,10.199.246.140,54325)\n",
      "  (15,10.199.246.147,54321)\n",
      "  (16,10.199.246.147,54323)\n",
      "  (17,10.199.246.147,54325)\n",
      "  (18,10.199.246.150,54321)\n",
      "  (19,10.199.246.150,54323)\n",
      "  (20,10.199.246.150,54325)\n",
      "  (21,10.199.246.154,54321)\n",
      "  (22,10.199.246.154,54323)\n",
      "  (23,10.199.246.155,54321)\n",
      "  (24,10.199.246.155,54323)\n",
      "  (25,10.199.246.155,54325)\n",
      "  (26,10.199.246.158,54321)\n",
      "  (27,10.199.246.158,54323)\n",
      "  (28,10.199.246.158,54325)\n",
      "  (29,10.199.246.180,54321)\n",
      "  (30,10.199.246.180,54323)\n",
      "  (31,10.199.246.180,54325)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://msk-wrk-devgpu01.megafon.ru:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n",
      " * Yarn App ID of Spark application: application_1590480401414_28828\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OContext.show of >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = H2OConf() \\\n",
    "         .setExternalClusterMode() \\\n",
    "         .useAutoClusterStart() \\\n",
    "         .setH2ODriverPath(h2o_pysparkling) # path_to_h2o_driver\n",
    "#         .setClusterSize(1) # Number of H2O worker nodes to start\n",
    "#         .setMapperXmx(\"2G\") # Memory per single H2O worker node\n",
    "#         .setYARNQueue(\"name\")\n",
    "       \n",
    "\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.199.246.132:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 min 11 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>15 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-pkrylov_application_1590480401414_28828</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>457.0 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>218</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://10.199.246.132:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.10 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         1 min 11 secs\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.6\n",
       "H2O_cluster_version_age:    15 days\n",
       "H2O_cluster_name:           sparkling-water-pkrylov_application_1590480401414_28828\n",
       "H2O_cluster_total_nodes:    32\n",
       "H2O_cluster_free_memory:    457.0 Gb\n",
       "H2O_cluster_total_cores:    218\n",
       "H2O_cluster_allowed_cores:  64\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://10.199.246.132:54321\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         XGBoost, Algos, Amazon S3, Sparkling Water REST API Extensions, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.10 final\n",
       "--------------------------  -------------------------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.30.0.6-1-2.3\n",
      " * H2O name: pkrylov\n",
      " * cluster size: 32\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,10.199.246.132,54321)\n",
      "  (1,10.199.246.132,54323)\n",
      "  (2,10.199.246.132,54325)\n",
      "  (3,10.199.246.133,54321)\n",
      "  (4,10.199.246.133,54323)\n",
      "  (5,10.199.246.133,54325)\n",
      "  (6,10.199.246.137,54321)\n",
      "  (7,10.199.246.137,54323)\n",
      "  (8,10.199.246.137,54325)\n",
      "  (9,10.199.246.139,54321)\n",
      "  (10,10.199.246.139,54323)\n",
      "  (11,10.199.246.139,54325)\n",
      "  (12,10.199.246.140,54321)\n",
      "  (13,10.199.246.140,54323)\n",
      "  (14,10.199.246.140,54325)\n",
      "  (15,10.199.246.147,54321)\n",
      "  (16,10.199.246.147,54323)\n",
      "  (17,10.199.246.147,54325)\n",
      "  (18,10.199.246.150,54321)\n",
      "  (19,10.199.246.150,54323)\n",
      "  (20,10.199.246.150,54325)\n",
      "  (21,10.199.246.154,54321)\n",
      "  (22,10.199.246.154,54323)\n",
      "  (23,10.199.246.155,54321)\n",
      "  (24,10.199.246.155,54323)\n",
      "  (25,10.199.246.155,54325)\n",
      "  (26,10.199.246.158,54321)\n",
      "  (27,10.199.246.158,54323)\n",
      "  (28,10.199.246.158,54325)\n",
      "  (29,10.199.246.180,54321)\n",
      "  (30,10.199.246.180,54323)\n",
      "  (31,10.199.246.180,54325)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://msk-wrk-devgpu01.megafon.ru:54321 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n",
      " * Yarn App ID of Spark application: application_1590480401414_28828\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "hc = H2OContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysparkling.ml import H2OXGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hadoop jar /home/pkrylov/h2o/h2odriver.jar -baseport 50001 -n 2 -mapperXmx 6g -jobnam\n",
    "\n",
    "Job name 'h2o' submitted\n",
    "JobTracker job ID is 'job_1590480401414_28730'\n",
    "For YARN users, logs command is 'yarn logs -applicationId application_1590480401414_28730'\n",
    "Waiting for H2O cluster to come up...\n",
    "H2O node 10.199.246.139:50001 is joining the cluster\n",
    "H2O node 10.199.246.139:50003 is joining the cluster\n",
    "Sending flatfiles to nodes...\n",
    "    [Sending flatfile to node 10.199.246.139:50001]\n",
    "    [Sending flatfile to node 10.199.246.139:50003]\n",
    "H2O node 10.199.246.139:50001 reports H2O cluster size 1 [leader is 10.199.246.139:10.199.246.139]\n",
    "H2O node 10.199.246.139:50003 reports H2O cluster size 1 [leader is 10.199.246.139:10.199.246.139]\n",
    "H2O node 10.199.246.139:50001 reports H2O cluster size 2 [leader is 10.199.246.139:10.199.246.139]\n",
    "H2O node 10.199.246.139:50003 reports H2O cluster size 2 [leader is 10.199.246.139:10.199.246.139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://10.199.246.139:50001 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 day 6 hours 14 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>12 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>h2o</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>10.33 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://10.199.246.139:50001</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.10 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         1 day 6 hours 14 mins\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.6\n",
       "H2O_cluster_version_age:    12 days\n",
       "H2O_cluster_name:           h2o\n",
       "H2O_cluster_total_nodes:    2\n",
       "H2O_cluster_free_memory:    10.33 Gb\n",
       "H2O_cluster_total_cores:    64\n",
       "H2O_cluster_allowed_cores:  64\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://10.199.246.139:50001\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.10 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(ip ='10.199.246.139', port=50001)\n",
    "\n",
    "# param ip: The ip address (or host name) of the server where H2O is running.\n",
    "# param port: Port number that H2O service is listening to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda's Python 3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
